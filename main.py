from llama import run_model

response = run_model("How should i hold a glass of chilled white wine")
print(response)
